import speech_recognition as sr
import pyttsx3
import numpy as np
import json
import os
import pickle
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.text import tokenizer_from_json
from tensorflow.keras.preprocessing.text import text_to_word_sequence

# ğŸš€ Inicializar voz
voz = pyttsx3.init()
voz.setProperty('rate', 150)

def falar(texto):
    print("IA:", texto)
    voz.say(texto)
    voz.runAndWait()

def ouvir():
    reconhecedor = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ Fale algo...")
        reconhecedor.adjust_for_ambient_noise(source)
        audio = reconhecedor.listen(source)

        try:
            texto = reconhecedor.recognize_google(audio, language='pt-BR')
            print("VocÃª disse:", texto)
            return texto
        except sr.UnknownValueError:
            falar("Desculpe, nÃ£o entendi.")
            return ""
        except sr.RequestError:
            falar("Erro de conexÃ£o com o serviÃ§o de voz.")
            return ""

# ğŸš¨ HistÃ³rico salvo
ARQUIVO_HISTORICO = "historico_interacoes.json"

# ğŸ” Carregar histÃ³rico salvo (ou iniciar novo)
if os.path.exists(ARQUIVO_HISTORICO):
    try:    
        with open(ARQUIVO_HISTORICO, "r", encoding="utf-8") as f:
            historico = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        print("âš ï¸  HistÃ³rico invÃ¡lido ou ausente. Iniciando lista vazia.")
        historico = []
else:
    historico = []

# ğŸ” Carregar tokenizer
try:
    with open("tokenizer.pkl", "rb") as f:
        tokenizer = pickle.load(f)
except FileNotFoundError:
    print("âš ï¸  Tokenizer nÃ£o encontrado. Criando um novo...")
    from tensorflow.keras.preprocessing.text import Tokenizer
    tokenizer = Tokenizer(num_words=1000)


def salvar_historico(frase, classe):
    historico.append({"frase": frase, "classe": int(round(classe))})
    with open(ARQUIVO_HISTORICO, "w", encoding="utf-8") as f:
        json.dump(historico, f, ensure_ascii=False, indent=4)

def treinar_novamente():
    frases = [item["frase"] for item in historico]
    classes = [item["classe"] for item in historico]

    tokenizer.fit_on_texts(frases)
    sequencias = tokenizer.texts_to_sequences(frases)
    X = pad_sequences(sequencias, maxlen=10)
    y = np.array(classes)

    # ğŸ§  Modelo mais profundo e eficaz
    modelo = Sequential()
    modelo.add(Dense(64, input_shape=(10,), activation='relu'))
    modelo.add(Dense(32, activation='relu'))
    modelo.add(Dense(1, activation='sigmoid'))

    modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    # â±ï¸ Mais tempo de treino
    modelo.fit(X, y, epochs=30, verbose=0)

    modelo.save("modelo_sentimentos.h5")

    with open("tokenizer.pkl", "wb") as f:
        pickle.dump(tokenizer, f)



# ğŸ” Carregar modelo (o mais recente)
try:
    modelo = load_model("modelo_sentimentos.h5")
except (OSError, IOError):
    print("âš ï¸  Modelo nÃ£o encontrado. Treinando um novo com o histÃ³rico...")
    treinar_novamente()
    modelo = load_model("modelo_sentimentos.h5")


import random  # no inÃ­cio do seu script

respostas_positivas = [
    "VocÃª parece Ã³timo hoje, senhor.",
    "Excelentes sinais de humor. Impressionante.",
    "Mais positivo que isso sÃ³ um pÃ´r do sol com cafÃ©.",
    "Claramente um dia de conquistas para vocÃª.",
    "Isso sim Ã© energia boa, mantenha assim."
]

respostas_neutras = [
    "VocÃª parece... ok. Meio termo Ã© aceitÃ¡vel.",
    "Nada empolga, nada irrita. Um dia normal.",
    "Humor estÃ¡vel. Siga em frente com cautela.",
    "Sem grandes emoÃ§Ãµes detectadas.",
    "Neutro como um robÃ´ com cafÃ© morno."
]

respostas_negativas = [
    "Detectei traÃ§os de tormento interior. Recomendo chocolate.",
    "Sinal de alerta: energia emocional em baixa.",
    "Humor sombrio. Hora de reavaliar sua playlist.",
    "Parece que o dia nÃ£o colaborou muito, nÃ©?",
    "Sinto uma sombra de tristeza aÃ­. Deseja conversar?"
]

def analisar_sentimento(frase):
    sequencia = tokenizer.texts_to_sequences([frase])
    entrada = pad_sequences(sequencia, maxlen=10)
    predicao = modelo.predict(entrada)[0][0]

    print(f"ğŸ¯ PrediÃ§Ã£o bruta: {predicao:.2f}")  # mostra no terminal

    # Salvar no histÃ³rico
    salvar_historico(frase, predicao)
    treinar_novamente()

    # Escolher resposta com base na faixa
    if predicao > 0.7:
        return random.choice(respostas_positivas)
    elif predicao > 0.4:
        return random.choice(respostas_neutras)
    else:
        return random.choice(respostas_negativas)


# ğŸ¤ Loop de interaÃ§Ã£o
while True:
    comando = ouvir().lower()

    if "sair" in comando or "encerrar" in comando:
        falar("Encerrando. Espero que seu humor melhore... ou nÃ£o.")
        break

    elif comando:
        resposta = analisar_sentimento(comando)
        falar(resposta)
